---
title: "tgw vs vpc peering"
categories:
 - aws
 - network
 - 모든_서비스를_k8s로_옮기면??
 - fargate_eks지원_서울에도_좀..
---
2020년 4월 ```tgw inter-region peering``` 기능이 나왔다.  
네트워크 토폴로지는 vpc peering을 쓰니 자연스럽게? Mesh형(부분연결형)으로 구성되어 있었다.  
VPC가 하나 더 추가될 때마다 통신이 필요한 VPC들끼리 peering을 해줘야하는데 관리하기가 쉽지않았다.  
routing table도 지저분해지고 네트워크 구성도를 그리려면 ,,,,,,, ㄷㄷ

네트워크 토폴로지를 Star형으로 바꾸어 라우팅테이블을 쉽게 관리하기위해 올해 초부터 tgw를 써보려고 했다.  
버지니아와 서울 리전 두군데를 쓰기때문에 리전간 피어링이 필수였고, 이 때는 tgw가 서울에 리전간 피어링을 지원하지 않았다.  
그래서 각각 리전안에서의 통신은 tgw, 다른리전과의 통신은 peering전용 vpc를 만들어서 vpc peering을 이용하려고 해보았다.

```console
vpc1 - tgwA - vpc2 <-peering-> vpc3 - tgwB - vpc4
```

라우팅 테이블만 봤을 때는 잘 될 것 같았는데 ```vpc1```과 ```vpc4```는 연결이 되지않았고 담당 TAM분도 테스트해보았는데 되지않는다고 답변을 받았다.  
그래서 계속 복잡한 Mesh형 토폴로지를 운영했었는데 얼마뒤 [inter-region peering이 서울에도 지원](https://aws.amazon.com/about-aws/whats-new/2020/04/aws-transit-gateway-now-supports-inter-region-peering-in-11-additional-regions/)되어 바로 tgw로 네트워크를 구성하였다.

개발환경 네트워크에 테스트한 후 점검 시간에 운영환경에 적용했더니 soeul b AZ에 트래픽이 간헐적으로 끊기는 현상이 발생했다.
멘붕이 오고 바로 다시 vpc peering으로 전환했다.  
개발환경에서 seoul b AZ의 ec2로 테스트하는 것을 놓쳤던 것 같다.  
case open했고 aws버그가 조치된 뒤 tgw를 새로 다시 만들어서 구축하라는 답변을 받았다.

그 외 office - aws VPN을 tgw로 연결하는 작업도 있었고, tgw로 옮기는 것이 간단할 것 같았는데 생각보다 이런저런 이슈들이 있었던 것 같다.  
tgw 장애를 대비해서 최소한의 vpc peering은 유지하고 장애 발생 시 routing table만 조정하면 되도록 해두었다.

### Cost
- tgw가 더 비싸다.
- vpc peering은 별도 비용은 없고 vpc간의 트래픽만 비용으로 청구된다.
- tgw는 vpc간 트래픽 비용과 함께 vpc attachment별 비용이 발생한다.

### Performance
- vpc peering이 더 빠르다.(이론적으로)
- vpc peering일 때와 비교하여 중간에 tgw라는 hop이 추가되므로 latency가 늘어날 수 밖에 없는 구성이다.
- 그러나 확인하기 어려울정도의 차이라고 한다.

### Management
- tgw가 관리하기 더 편하다.
- Mesh topology, Star topology 특징